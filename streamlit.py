# app.py â€” ì˜ë£Œíê¸°ë¬¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ (Page 1: final_df ì¸ì‚¬ì´íŠ¸)
# ë°ì´í„°: final_df.csv (ì‹œë„ë³„ ì˜ë£Œíê¸°ë¬¼ + ë³‘ì›/ì˜ì› ìˆ˜ + ì¸êµ¬/ì¸í”„ë¼ ë“±)

from pathlib import Path
import json

import numpy as np
import pandas as pd
import altair as alt
import plotly.express as px
import streamlit as st

from ui_theme import apply_theme

apply_theme()   # ë˜ëŠ” "paper-light", "glass-dark"

def inject_custom_css():
    st.markdown(
        """
        <style>
        /* ì „ì²´ ì»¨í…Œì´ë„ˆ í­ & ì—¬ë°± */
        .main .block-container {
            max-width: 1200px;
            padding-top: 2rem;
            padding-bottom: 3rem;
        }

        /* íƒ€ì´í‹€ ê·¸ë¼ë°ì´ì…˜ */
        h1 {
            font-size: 2.6rem !important;
            font-weight: 800 !important;
            background: linear-gradient(90deg, #ff4b4b, #fb923c, #facc15);
            -webkit-background-clip: text;
            color: transparent;
        }

        /* ì‚¬ì´ë“œë°” ë°°ê²½ */
        [data-testid="stSidebar"] {
            background-color: #020617;
            border-right: 1px solid rgba(148, 163, 184, 0.3);
        }

        /* metric ì¹´ë“œ ì´ì˜ê²Œ */
        [data-testid="metric-container"] {
            background-color: #020617;
            border-radius: 0.75rem;
            padding: 1rem 1.2rem;
            border: 1px solid rgba(148, 163, 184, 0.4);
            box-shadow: 0 10px 30px rgba(15, 23, 42, 0.8);
        }
        [data-testid="metric-container"] > div {
            color: #e5e7eb !important;
        }

        /* expander ìŠ¤íƒ€ì¼ */
        details {
            border-radius: 0.75rem;
            background-color: #020617;
            border: 1px solid rgba(148, 163, 184, 0.4);
        }

        /* ë°ì´í„°í”„ë ˆì„ í—¤ë” */
        .stDataFrame thead tr th {
            background-color: #020617 !important;
            color: #e5e7eb !important;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

inject_custom_css()


# -------------------------------
# ê¸°ë³¸ ì„¤ì •
# -------------------------------
st.set_page_config(
    layout="wide",
    page_title="ì˜ë£Œíê¸°ë¬¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ§ª",
)
alt.data_transformers.disable_max_rows()
st.title("ì˜ë£Œíê¸°ë¬¼ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")


DATA_FILE = "data/final_df.csv"
GEO_FILE = "data/TL_SCCO_CTPRVN.json"  # ì§€ë„ íŒŒì¼ ì´ë¦„

# -------------------------------
# ê³µìš© ìœ í‹¸ í•¨ìˆ˜
# -------------------------------
def series_to_df(s: pd.Series, value_name: str, index_name: str) -> pd.DataFrame:
    s = s.copy()
    df_tmp = s.to_frame(value_name)
    idx_name = index_name if index_name not in df_tmp.columns else f"{index_name}_idx"
    df_tmp = df_tmp.rename_axis(idx_name).reset_index()
    if idx_name != index_name:
        df_tmp = df_tmp.rename(columns={idx_name: index_name})
    return df_tmp


@st.cache_data(show_spinner=False)
def load_data(path: str) -> pd.DataFrame:
    # ì—¬ëŸ¬ ì¸ì½”ë”©ì„ ìˆœì„œëŒ€ë¡œ ì‹œë„ (cp949, utf-8-sig, utf-8)
    encodings = ["cp949", "utf-8-sig", "utf-8"]

    last_err = None
    for enc in encodings:
        try:
            df = pd.read_csv(path, encoding=enc)
            break
        except UnicodeDecodeError as e:
            last_err = e
            continue
    else:
        st.error(f"CSV ì¸ì½”ë”©ì„ í•´ì„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\në§ˆì§€ë§‰ ì—ëŸ¬: {last_err}")
        st.stop()

    if "ì‹œë„" in df.columns:
        df["ì‹œë„"] = df["ì‹œë„"].astype(str).str.strip()
    return df

# ì‹œë„ â†’ TL_SCCO_CTPRVN.json ì˜ CTP_KOR_NM ë§¤í•‘
SIDO_TO_SHP = {
    "ì„œìš¸": "ì„œìš¸íŠ¹ë³„ì‹œ",
    "ë¶€ì‚°": "ë¶€ì‚°ê´‘ì—­ì‹œ",
    "ëŒ€êµ¬": "ëŒ€êµ¬ê´‘ì—­ì‹œ",
    "ì¸ì²œ": "ì¸ì²œê´‘ì—­ì‹œ",
    "ê´‘ì£¼": "ê´‘ì£¼ê´‘ì—­ì‹œ",
    "ëŒ€ì „": "ëŒ€ì „ê´‘ì—­ì‹œ",
    "ìš¸ì‚°": "ìš¸ì‚°ê´‘ì—­ì‹œ",
    "ì„¸ì¢…": "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ",
    "ê²½ê¸°": "ê²½ê¸°ë„",
    "ê°•ì›": "ê°•ì›ë„",
    "ì¶©ë¶": "ì¶©ì²­ë¶ë„",
    "ì¶©ë‚¨": "ì¶©ì²­ë‚¨ë„",
    "ì „ë¶": "ì „ë¼ë¶ë„",
    "ì „ë‚¨": "ì „ë¼ë‚¨ë„",
    "ê²½ë¶": "ê²½ìƒë¶ë„",
    "ê²½ë‚¨": "ê²½ìƒë‚¨ë„",
    "ì œì£¼": "ì œì£¼íŠ¹ë³„ìì¹˜ë„",
}



@st.cache_data(show_spinner=False)
def load_geojson(path: str):
    if not Path(path).exists():
        return None
    with open(path, encoding="utf-8") as f:
        return json.load(f)


# -------------------------------
# ë°ì´í„° ë¡œë”©
# -------------------------------
if not Path(DATA_FILE).exists():
    st.error(f"'{DATA_FILE}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°™ì€ í´ë”ì— final_df.csvë¥¼ ë‘ê³  ë‹¤ì‹œ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
    st.stop()

df_raw = load_data(DATA_FILE)


# ì£¼ìš” ì»¬ëŸ¼ ì´ë¦„ë“¤
TARGET_COL = "ì§€ì—­ë³„_ì˜ë£Œíê¸°ë¬¼"
TARGET_TRANS_COL = "ì§€ì—­ë³„_ì˜ë£Œíê¸°ë¬¼_TRANS"  # ìˆìœ¼ë©´ ì„ íƒí•´ì„œ ì‚¬ìš©
DENTAL_COL = "ì¹˜ê³¼ë³‘ì›"
REHAB_COL = "ìš”ì–‘ë³‘ì›"
INFRA_COL = "ì˜ë£Œì¸í”„ë¼_ê°•ë„"

FACILITY_HOSP_COLS = [
    "ìƒê¸‰ì¢…í•©ë³‘ì›",
    "ì¢…í•©ë³‘ì›",
    "ì¹˜ê³¼ë³‘ì›",
    "í•œë°©ë³‘ì›",
    "ìš”ì–‘ë³‘ì›",
    "ì •ì‹ ë³‘ì›",
]
FACILITY_CLINIC_COLS = ["ì˜ì›", "ì¹˜ê³¼ì˜ì›", "í•œì˜ì›"]

# -------------------------------
# ì‚¬ì´ë“œë°” í•„í„°
# -------------------------------
with st.sidebar:
    st.header("í•„í„°")

    df = df_raw.copy()

    # ì—°ë„ í•„í„°
    if "ì—°ë„" in df.columns:
        years = sorted(df["ì—°ë„"].dropna().unique().tolist())
        sel_years = st.multiselect("ì—°ë„ ì„ íƒ", options=years, default=years)
        if sel_years:
            df = df[df["ì—°ë„"].isin(sel_years)]
        st.caption(f"ì„ íƒëœ ì—°ë„: {', '.join(map(str, sel_years)) if sel_years else 'ì „ì²´'}")
    else:
        st.info("ì—°ë„ ì»¬ëŸ¼ì´ ì—†ì–´ ì—°ë„ í•„í„°ëŠ” í‘œì‹œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    # ì‹œë„ í•„í„°
    if "ì‹œë„" in df.columns:
        sidos = sorted(df["ì‹œë„"].dropna().unique().tolist())
        sel_sidos = st.multiselect("ì‹œë„ ì„ íƒ", options=sidos, default=sidos)
        if sel_sidos:
            df = df[df["ì‹œë„"].isin(sel_sidos)]
        st.caption(f"ì„ íƒëœ ì‹œë„: {', '.join(sel_sidos) if sel_sidos else 'ì „ì²´'}")

    # íƒ€ê¹ƒ(ì›ë³¸ vs ë³€í™˜) ì„ íƒ
    target_options = []
    if TARGET_COL in df.columns:
        target_options.append(("ì›ë³¸ (ì§€ì—­ë³„_ì˜ë£Œíê¸°ë¬¼)", TARGET_COL))
    if TARGET_TRANS_COL in df.columns:
        target_options.append(("ë³€í™˜ê°’ (ì§€ì—­ë³„_ì˜ë£Œíê¸°ë¬¼_TRANS)", TARGET_TRANS_COL))

    if not target_options:
        st.error("ì˜ë£Œíê¸°ë¬¼ ì»¬ëŸ¼(ì§€ì—­ë³„_ì˜ë£Œíê¸°ë¬¼)ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        st.stop()

    label_list = [lbl for lbl, _ in target_options]
    default_idx = 1 if len(target_options) > 1 else 0
    sel_label = st.radio("ì˜ë£Œíê¸°ë¬¼ ì§€í‘œ ì„ íƒ", label_list, index=default_idx)
    TARGET_USED = dict(target_options)[sel_label]
    st.caption(f"ë¶„ì„ íƒ€ê¹ƒ: **{TARGET_USED}**")

# -------------------------------
# ìƒë‹¨ KPI ì¹´ë“œ
# -------------------------------
st.subheader("ìš”ì•½ ì§€í‘œ")

k1, k2, k3, k4 = st.columns(4)

# KPIëŠ” ì„ íƒëœ íƒ€ê¹ƒ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°
target_series = df[TARGET_USED]
total_waste = target_series.sum()

if "ì‹œë„" in df.columns:
    mean_waste_per_region = df.groupby("ì‹œë„")[TARGET_USED].sum().mean()
else:
    mean_waste_per_region = np.nan

if DENTAL_COL in df.columns:
    total_dental = df[DENTAL_COL].sum()
    waste_per_dental = total_waste / total_dental if total_dental > 0 else np.nan
else:
    waste_per_dental = np.nan

if "ì‹œë„" in df.columns:
    top_region = (
        df.groupby("ì‹œë„")[TARGET_USED]
        .sum()
        .sort_values(ascending=False)
        .head(1)
    )
    top_region_name = top_region.index[0]
    top_region_val = float(top_region.iloc[0])
else:
    top_region_name, top_region_val = "-", np.nan

with k1:
    st.metric("ì´ ì˜ë£Œíê¸°ë¬¼ (ì„ íƒ ì§€í‘œ í•©ê³„)", f"{total_waste:,.0f}")
with k2:
    if not np.isnan(mean_waste_per_region):
        st.metric("ì‹œë„ë³„ í‰ê·  ì˜ë£Œíê¸°ë¬¼", f"{mean_waste_per_region:,.0f}")
    else:
        st.metric("ì‹œë„ë³„ í‰ê·  ì˜ë£Œíê¸°ë¬¼", "N/A")
with k3:
    if not np.isnan(waste_per_dental):
        st.metric("ì¹˜ê³¼ë³‘ì› 1ê¸°ê´€ë‹¹ í‰ê·  ì˜ë£Œíê¸°ë¬¼", f"{waste_per_dental:,.1f}")
    else:
        st.metric("ì¹˜ê³¼ë³‘ì› 1ê¸°ê´€ë‹¹ í‰ê·  ì˜ë£Œíê¸°ë¬¼", "N/A")
with k4:
    st.metric(
        "ì˜ë£Œíê¸°ë¬¼ ìµœë‹¤ ë°°ì¶œ ì‹œë„",
        f"{top_region_name} ({top_region_val:,.0f})" if not np.isnan(top_region_val) else "N/A",
    )

st.caption("â€» ë³€í™˜ê°’(TRANS)ì„ ì„ íƒí•œ ê²½ìš°, ì ˆëŒ€ëŸ‰(í†¤)ì´ ì•„ë‹Œ 'ìƒëŒ€ ì§€í‘œ'ë¡œ í•´ì„í•´ì•¼ í•©ë‹ˆë‹¤.")
st.markdown("---")

# -------------------------------
# íƒ­ ë ˆì´ì•„ì›ƒ (ì‹œì„¤ìœ í˜• íƒ­ ì œê±° â†’ 3ê°œ íƒ­ë§Œ ì‚¬ìš©)
# -------------------------------
tab1, tab2, tab3 = st.tabs(
    ["ì‹œë„ë³„ ë¹„êµ", "ìƒê´€Â·íšŒê·€ ë¶„ì„", "ì˜ë£Œ ì¸í”„ë¼(SEM ê´€ì )"]
)

# -------------------------------
# Tab1: ì‹œë„ë³„ ì˜ë£Œíê¸°ë¬¼ + ì§€ë„
# -------------------------------
with tab1:
    st.markdown("### ì‹œë„ë³„ ì˜ë£Œíê¸°ë¬¼ ë¹„êµ")

    if {"ì‹œë„", TARGET_USED}.issubset(df.columns):
        grouped = df.groupby("ì‹œë„", as_index=False).agg(
            ì˜ë£Œíê¸°ë¬¼=(TARGET_USED, "sum"),
            ì¹˜ê³¼ë³‘ì›=(DENTAL_COL, "sum") if DENTAL_COL in df.columns else ("ì‹œë„", "size"),
        )
        if DENTAL_COL in df.columns:
            grouped["ì¹˜ê³¼ë³‘ì›_ë‹¹_íê¸°ë¬¼"] = grouped["ì˜ë£Œíê¸°ë¬¼"] / grouped["ì¹˜ê³¼ë³‘ì›"].replace(0, np.nan)

        c1, c2 = st.columns([2, 1], gap="large")

        with c1:
            base = grouped.sort_values(
                "ì¹˜ê³¼ë³‘ì›_ë‹¹_íê¸°ë¬¼" if "ì¹˜ê³¼ë³‘ì›_ë‹¹_íê¸°ë¬¼" in grouped.columns else "ì˜ë£Œíê¸°ë¬¼"
            )
            bar = (
                alt.Chart(base)
                .mark_bar()
                .encode(
                    x=alt.X("ì‹œë„:N", sort=None),
                    y=alt.Y(
                        "ì¹˜ê³¼ë³‘ì›_ë‹¹_íê¸°ë¬¼:Q",
                        title="ì¹˜ê³¼ë³‘ì› 1ê¸°ê´€ë‹¹ ì˜ë£Œíê¸°ë¬¼(ì„ íƒ ì§€í‘œ)",
                    )
                    if "ì¹˜ê³¼ë³‘ì›_ë‹¹_íê¸°ë¬¼" in base.columns
                    else alt.Y("ì˜ë£Œíê¸°ë¬¼:Q", title="ì˜ë£Œíê¸°ë¬¼(ì„ íƒ ì§€í‘œ)"),
                    tooltip=base.columns.tolist(),
                )
                .properties(width="container", height=380)
            )
            st.altair_chart(bar, use_container_width=True)

        with c2:
            line = (
                alt.Chart(grouped)
                .transform_fold(
                    ["ì˜ë£Œíê¸°ë¬¼", "ì¹˜ê³¼ë³‘ì›"],
                    as_=["ì§€í‘œ", "ê°’"],
                )
                .mark_line(point=True)
                .encode(
                    x=alt.X("ì‹œë„:N", sort=None),
                    y=alt.Y("ê°’:Q", title="ê°’(ì„ íƒ ì§€í‘œ / ê¸°ê´€ìˆ˜)"),
                    color="ì§€í‘œ:N",
                    tooltip=["ì‹œë„:N", "ì§€í‘œ:N", "ê°’:Q"],
                )
                .properties(height=380)
            )
            st.altair_chart(line, use_container_width=True)

        # ì§€ë„ ì‹œê°í™”
        st.markdown("#### ì‹œë„ë³„ ì˜ë£Œíê¸°ë¬¼ ì§€ë¦¬ì  ë¶„í¬")

        geo_data = load_geojson(GEO_FILE)
        if geo_data is not None:
            map_agg = grouped[["ì‹œë„", "ì˜ë£Œíê¸°ë¬¼"]].copy()
            map_agg["CTP_KOR_NM"] = map_agg["ì‹œë„"].map(SIDO_TO_SHP).fillna(map_agg["ì‹œë„"])

            fig = px.choropleth(
                map_agg,
                geojson=geo_data,
                locations="CTP_KOR_NM",
                featureidkey="properties.CTP_KOR_NM",
                color="ì˜ë£Œíê¸°ë¬¼",
                color_continuous_scale="OrRd",
                labels={"ì˜ë£Œíê¸°ë¬¼": "ì˜ë£Œíê¸°ë¬¼(ì„ íƒ ì§€í‘œ)"},
                hover_data={"ì‹œë„": True, "ì˜ë£Œíê¸°ë¬¼": ":,.0f"},
                title="ì‹œë„ë³„ ì˜ë£Œíê¸°ë¬¼ (í•©ê³„, ì„ íƒ ì§€í‘œ)",
            )
            fig.update_geos(fitbounds="locations", visible=False)
            fig.update_layout(height=450, margin=dict(l=0, r=0, t=60, b=0))
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info(f"'{GEO_FILE}' íŒŒì¼ì´ ì—†ì–´ ì§€ë„ ì‹œê°í™”ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")

    else:
        st.warning("ì‹œë„ ë˜ëŠ” ì˜ë£Œíê¸°ë¬¼ ì»¬ëŸ¼ì´ ì—†ì–´ ì‹œë„ë³„ ë¹„êµë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# -------------------------------
# Tab2: ìƒê´€Â·íšŒê·€ ë¶„ì„
# -------------------------------
with tab2:
    st.markdown("### ì˜ë£Œíê¸°ë¬¼ê³¼ ì˜ë£Œ ì¸í”„ë¼ ì§€í‘œ ê°„ ìƒê´€Â·íšŒê·€ ë¶„ì„")

    if TARGET_USED not in df.columns:
        st.warning("ì„ íƒëœ ì˜ë£Œíê¸°ë¬¼ ì»¬ëŸ¼ì´ ì—†ì–´ ìƒê´€ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        corr = df[numeric_cols].corr()[TARGET_USED].drop(labels=[TARGET_USED])
        corr_df = corr.sort_values(ascending=False).to_frame("Pearson r")
        corr_df["abs_r"] = corr_df["Pearson r"].abs()
        corr_df = corr_df.sort_values("abs_r", ascending=True)

        st.markdown("**ì˜ë£Œíê¸°ë¬¼ê³¼ì˜ ìƒê´€ê³„ìˆ˜ (ìƒëŒ€ì ìœ¼ë¡œ í° ê²ƒì¼ìˆ˜ë¡ ì˜í–¥ë ¥ ê°€ëŠ¥ì„±â†‘)**")
        corr_chart = (
            alt.Chart(corr_df.reset_index())
            .mark_bar()
            .encode(
                x=alt.X("Pearson r:Q"),
                y=alt.Y("index:N", title="ë³€ìˆ˜ëª…", sort="-x"),
                color=alt.Color("Pearson r:Q", scale=alt.Scale(scheme="blueorange")),
                tooltip=["index", "Pearson r"],
            )
            .properties(height=max(280, 18 * len(corr_df)))
        )
        st.altair_chart(corr_chart, use_container_width=True)

        st.markdown("---")
        st.markdown("#### íŠ¹ì • ì‹œì„¤ ìˆ˜ vs ì˜ë£Œíê¸°ë¬¼ (ì‚°ì ë„ + íšŒê·€ì„ )")

        candidate_xcols = [c for c in FACILITY_HOSP_COLS + FACILITY_CLINIC_COLS if c in df.columns]
        if not candidate_xcols:
            candidate_xcols = [c for c in numeric_cols if c != TARGET_USED]

        sel_x = st.selectbox("xì¶• ë³€ìˆ˜ ì„ íƒ", options=candidate_xcols, index=0)

        # ë¡œê·¸ ìŠ¤ì¼€ì¼ ì˜µì…˜
        col_log1, col_log2 = st.columns(2)
        with col_log1:
            use_log_x = st.checkbox("xì¶• ë¡œê·¸ ìŠ¤ì¼€ì¼", value=False)
        with col_log2:
            use_log_y = st.checkbox("yì¶• ë¡œê·¸ ìŠ¤ì¼€ì¼", value=False)

        scatter_df = df[[sel_x, TARGET_USED]].dropna()

        x_enc = alt.X(
            f"{sel_x}:Q",
            title=sel_x,
            scale=alt.Scale(type="log") if use_log_x else alt.Undefined,
        )
        y_enc = alt.Y(
            f"{TARGET_USED}:Q",
            title="ì˜ë£Œíê¸°ë¬¼(ì„ íƒ ì§€í‘œ)",
            scale=alt.Scale(type="log") if use_log_y else alt.Undefined,
        )

        sc = (
            alt.Chart(scatter_df)
            .mark_circle(size=60, opacity=0.7)
            .encode(
                x=x_enc,
                y=y_enc,
                tooltip=[sel_x, TARGET_USED],
            )
        )

        reg = sc.transform_regression(sel_x, TARGET_USED, method="linear").mark_line(color="orange")

        st.altair_chart(sc + reg, use_container_width=True)
        st.caption("â€» ì  í•˜ë‚˜ëŠ” (ì‹œë„Ã—ì—°ë„) ë‹¨ìœ„ í•˜ë‚˜ë¥¼ ì˜ë¯¸. ì§ì„  ê¸°ìš¸ê¸°ëŠ” ë‹¨ìˆœ ì„ í˜•íšŒê·€ ê³„ìˆ˜ì— í•´ë‹¹.")

# -------------------------------
# Tab3: ì˜ë£Œ ì¸í”„ë¼(SEM ê´€ì )
# -------------------------------
with tab3:
    st.markdown("### ì˜ë£Œ ì¸í”„ë¼ ê°•ë„ì™€ ì˜ë£Œíê¸°ë¬¼ (SEM êµ¬ì¡° í•´ì„ìš©)")

    if {INFRA_COL, DENTAL_COL, REHAB_COL}.issubset(df.columns) and TARGET_USED in df.columns:
        info_col1, info_col2 = st.columns([2, 1])

        with info_col1:
            st.markdown(
                """
**ê°€ì„¤(H4)**  

- ì¹˜ê³¼ë³‘ì›Â·ìš”ì–‘ë³‘ì› ì¦ê°€ â†’ ì˜ë£Œì¸í”„ë¼ ê°•ë„ ì¦ê°€  
- ì˜ë£Œì¸í”„ë¼ ê°•ë„ ì¦ê°€ â†’ ì˜ë£Œíê¸°ë¬¼ ì¦ê°€ (ë˜ëŠ” íš¨ìœ¨ì„± íš¨ê³¼ë¡œ ê°ì†Œ)  

ì´ íƒ­ì€ ìœ„ SEM êµ¬ì¡°ë¥¼ ì´í•´í•˜ê¸° ìœ„í•œ ê¸°ì´ˆ EDAë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.
                """
            )

        with info_col2:
            # ê°„ë‹¨ ìš”ì•½ ë©”íŠ¸ë¦­
            mean_infra = df[INFRA_COL].mean()
            mean_target = df[TARGET_USED].mean()
            r_infra_target = np.corrcoef(
                df[INFRA_COL].fillna(0), df[TARGET_USED].fillna(0)
            )[0, 1]

            st.metric("í‰ê·  ì˜ë£Œì¸í”„ë¼ ê°•ë„", f"{mean_infra:,.1f}")
            st.metric("í‰ê·  ì˜ë£Œíê¸°ë¬¼(ì„ íƒ ì§€í‘œ)", f"{mean_target:,.1f}")
            st.metric("ì¸í”„ë¼ ê°•ë„ â†” ì˜ë£Œíê¸°ë¬¼ ìƒê´€(r)", f"{r_infra_target:,.3f}")

        # 1) ì¹˜ê³¼ë³‘ì›/ìš”ì–‘ë³‘ì› â†’ ì˜ë£Œì¸í”„ë¼ ê°•ë„
        st.markdown("#### (1) ì¹˜ê³¼ë³‘ì›Â·ìš”ì–‘ë³‘ì› vs ì˜ë£Œì¸í”„ë¼ ê°•ë„")

        infra_base = df[[INFRA_COL, DENTAL_COL, REHAB_COL]].dropna().copy()
        infra_long = infra_base.melt(
            id_vars=[INFRA_COL],
            value_vars=[DENTAL_COL, REHAB_COL],
            var_name="ì‹œì„¤",
            value_name="value",
        )

        infra_scatter = (
            alt.Chart(infra_long)
            .mark_circle(size=60, opacity=0.7)
            .encode(
                x=alt.X("value:Q", title="ì‹œì„¤ ìˆ˜"),
                y=alt.Y(f"{INFRA_COL}:Q", title="ì˜ë£Œì¸í”„ë¼ ê°•ë„"),
                color=alt.Color("ì‹œì„¤:N", title="ì‹œì„¤ ìœ í˜•"),
                tooltip=["ì‹œì„¤:N", "value:Q", alt.Tooltip(f"{INFRA_COL}:Q", title="ì˜ë£Œì¸í”„ë¼ ê°•ë„")],
            )
            .properties(height=360)
        )
        st.altair_chart(infra_scatter, use_container_width=True)

        # 2) ì˜ë£Œì¸í”„ë¼ ê°•ë„ vs ì˜ë£Œíê¸°ë¬¼
        st.markdown("#### (2) ì˜ë£Œì¸í”„ë¼ ê°•ë„ vs ì˜ë£Œíê¸°ë¬¼")

        infra_waste_df = df[[INFRA_COL, TARGET_USED]].dropna()
        sc2 = (
            alt.Chart(infra_waste_df)
            .mark_circle(size=60, opacity=0.7)
            .encode(
                x=alt.X(f"{INFRA_COL}:Q", title="ì˜ë£Œì¸í”„ë¼ ê°•ë„"),
                y=alt.Y(f"{TARGET_USED}:Q", title="ì˜ë£Œíê¸°ë¬¼(ì„ íƒ ì§€í‘œ)"),
                tooltip=[INFRA_COL, TARGET_USED],
            )
        )
        reg2 = sc2.transform_regression(INFRA_COL, TARGET_USED, method="linear").mark_line(color="orange")
        st.altair_chart(sc2 + reg2, use_container_width=True)

        # ë‹¨ìˆœ íšŒê·€ì‹ ìš”ì•½
        x = infra_waste_df[INFRA_COL].values
        y = infra_waste_df[TARGET_USED].values
        if len(x) > 1:
            b1, b0 = np.polyfit(x, y, 1)
            r = np.corrcoef(x, y)[0, 1]
            r2 = r**2

        # 3) ì§€ë„ ì‹œê°í™”: ì‹œë„ë³„ ì§€ë¦¬ì  ë¶„í¬ (ë³€ìˆ˜ ì„ íƒ)
        st.markdown("#### (3) ì‹œë„ë³„ ì§€ë¦¬ì  ë¶„í¬ (ì§€ë„)")

        if "ì‹œë„" in df.columns:
            # ì‹œë„ë³„ ì§‘ê³„: ì¸í”„ë¼ ê°•ë„ í‰ê· , ì˜ë£Œíê¸°ë¬¼ í•©ê³„, ì¹˜ê³¼/ìš”ì–‘ë³‘ì› í•©ê³„
            agg_dict = {
                INFRA_COL: (INFRA_COL, "mean"),
                TARGET_USED: (TARGET_USED, "sum"),
            }
            if DENTAL_COL in df.columns:
                agg_dict[DENTAL_COL] = (DENTAL_COL, "sum")
            if REHAB_COL in df.columns:
                agg_dict[REHAB_COL] = (REHAB_COL, "sum")

            map_agg = df.groupby("ì‹œë„", as_index=False).agg(**agg_dict)

            # ì‹œë„ëª…ì„ ì§€ë„ íŒŒì¼ì˜ CTP_KOR_NMìœ¼ë¡œ ë§¤í•‘
            map_agg["CTP_KOR_NM"] = map_agg["ì‹œë„"].map(SIDO_TO_SHP).fillna(map_agg["ì‹œë„"])

            # GeoJSON ë¡œë“œ
            geo_data = load_geojson(GEO_FILE)

            if geo_data is not None:
                # ì§€ë„ì—ì„œ ì„ íƒí•  ìˆ˜ ìˆëŠ” ë³€ìˆ˜ë“¤
                map_var_options = {}
                if INFRA_COL in map_agg.columns:
                    map_var_options["ì˜ë£Œì¸í”„ë¼ ê°•ë„(í‰ê· )"] = INFRA_COL
                if TARGET_USED in map_agg.columns:
                    map_var_options["ì˜ë£Œíê¸°ë¬¼(í•©ê³„, ì„ íƒ ì§€í‘œ)"] = TARGET_USED
                if DENTAL_COL in map_agg.columns:
                    map_var_options["ì¹˜ê³¼ë³‘ì› ìˆ˜(í•©ê³„)"] = DENTAL_COL
                if REHAB_COL in map_agg.columns:
                    map_var_options["ìš”ì–‘ë³‘ì› ìˆ˜(í•©ê³„)"] = REHAB_COL

                if not map_var_options:
                    st.info("ì§€ë„ì— í‘œì‹œí•  ìˆ˜ ìˆëŠ” ìˆ˜ì¹˜í˜• ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    sel_label_map = st.selectbox(
                        "ì§€ë„ì— í‘œì‹œí•  ë³€ìˆ˜ ì„ íƒ",
                        options=list(map_var_options.keys()),
                        index=0,
                    )
                    map_var = map_var_options[sel_label_map]

                    fig_map = px.choropleth(
                        map_agg,
                        geojson=geo_data,
                        locations="CTP_KOR_NM",
                        featureidkey="properties.CTP_KOR_NM",
                        color=map_var,
                        color_continuous_scale="Blues",
                        labels={map_var: sel_label_map},
                        hover_data={
                            "ì‹œë„": True,
                            map_var: ":,.0f",
                        },
                        title=f"ì‹œë„ë³„ {sel_label_map}",
                    )
                    fig_map.update_geos(fitbounds="locations", visible=False)
                    fig_map.update_layout(height=500, margin=dict(l=0, r=0, t=60, b=0))
                    st.plotly_chart(fig_map, use_container_width=True)
            else:
                st.info(f"'{GEO_FILE}' íŒŒì¼ì´ ì—†ì–´ ì§€ë„ ì‹œê°í™”ë¥¼ ìƒëµí•©ë‹ˆë‹¤.")
        else:
            st.info("ì‹œë„ ì»¬ëŸ¼ì´ ì—†ì–´ ì§€ë„ ì‹œê°í™”ë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 4) ìƒê´€ê³„ìˆ˜ ìš”ì•½
        r1 = np.corrcoef(df[DENTAL_COL].fillna(0), df[INFRA_COL].fillna(0))[0, 1]
        r2 = np.corrcoef(df[REHAB_COL].fillna(0), df[INFRA_COL].fillna(0))[0, 1]
        r3 = np.corrcoef(df[INFRA_COL].fillna(0), df[TARGET_USED].fillna(0))[0, 1]

        st.markdown("#### (4) ìƒê´€ê³„ìˆ˜ ìš”ì•½ (SEM í•´ì„ìš© ì°¸ê³ ì¹˜)")
        st.write(
            f"- ì¹˜ê³¼ë³‘ì› â†” ì˜ë£Œì¸í”„ë¼ ê°•ë„: **r = {r1:.3f}**  \n"
            f"- ìš”ì–‘ë³‘ì› â†” ì˜ë£Œì¸í”„ë¼ ê°•ë„: **r = {r2:.3f}**  \n"
            f"- ì˜ë£Œì¸í”„ë¼ ê°•ë„ â†” ì˜ë£Œíê¸°ë¬¼: **r = {r3:.3f}**"
        )
    else:
        st.info(
            f"'{INFRA_COL}', '{DENTAL_COL}', '{REHAB_COL}' ì»¬ëŸ¼ì´ ëª¨ë‘ ìˆì–´ì•¼ ì¸í”„ë¼ íƒ­ì„ ê·¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )

# -------------------------------
# ìë™ ì¸ì‚¬ì´íŠ¸ ìš”ì•½ (ë³´ê³ ì„œìš© ë¬¸ì¥ ë½‘ê¸°)
# -------------------------------
st.markdown("---")
st.markdown("## ğŸ§¾ ìë™ ì¸ì‚¬ì´íŠ¸ ìš”ì•½")

insight_lines = []

# 1) ì´ëŸ‰ ê¸°ì¤€ Top3 ì‹œë„
if "ì‹œë„" in df.columns:
    reg_sum = df.groupby("ì‹œë„", as_index=False)[TARGET_USED].sum()
    reg_sum = reg_sum.sort_values(TARGET_USED, ascending=False)
    total_nat = reg_sum[TARGET_USED].sum()

    if len(reg_sum) >= 3:
        top3 = reg_sum.head(3)
        top3_names = ", ".join(top3["ì‹œë„"].tolist())
        top3_share = top3[TARGET_USED].sum() / total_nat * 100
        insight_lines.append(
            f"- **ì´ ì˜ë£Œíê¸°ë¬¼ Top3 ì‹œë„**ëŠ” {top3_names}ì´ë©°, "
            f"ì„¸ ì§€ì—­ì´ ì „ì²´ì˜ ì•½ **{top3_share:.1f}%**ë¥¼ ì°¨ì§€í•©ë‹ˆë‹¤."
        )

    # 1ê¸°ê´€ë‹¹ ë°°ì¶œëŸ‰(ì´ ì˜ë£Œê¸°ê´€ìˆ˜ ê¸°ì¤€)
    facility_col = None
    for cand in ["ì´_ì˜ë£Œê¸°ê´€ìˆ˜", "ì´_ë³‘ì˜ì›ìˆ˜"]:
        if cand in df.columns:
            facility_col = cand
            break

    if facility_col is not None:
        reg_fac = (
            df.groupby("ì‹œë„", as_index=False)[[TARGET_USED, facility_col]]
            .sum()
            .rename(columns={TARGET_USED: "waste", facility_col: "fac"})
        )
        reg_fac["waste_per_fac"] = reg_fac["waste"] / reg_fac["fac"].replace(0, np.nan)

        reg_fac = reg_fac.dropna(subset=["waste_per_fac"])
        if not reg_fac.empty:
            high = reg_fac.sort_values("waste_per_fac", ascending=False).head(1).iloc[0]
            low = reg_fac.sort_values("waste_per_fac", ascending=True).head(1).iloc[0]
            insight_lines.append(
                f"- **ê¸°ê´€ë‹¹ ë°°ì¶œëŸ‰ì´ ê°€ì¥ ë†’ì€ ì‹œë„**ëŠ” **{high['ì‹œë„']}**ë¡œ, "
                f"1ê¸°ê´€ë‹¹ í‰ê·  **{high['waste_per_fac']:.1f}** ë‹¨ìœ„ì˜ ì˜ë£Œíê¸°ë¬¼ì„ ë°°ì¶œí•©ë‹ˆë‹¤. "
                f"ë°˜ëŒ€ë¡œ **{low['ì‹œë„']}**ëŠ” ê¸°ê´€ë‹¹ ë°°ì¶œëŸ‰ì´ ê°€ì¥ ë‚®ìŠµë‹ˆë‹¤."
            )

# 2) ê³ ë ¹ì¸êµ¬ë¹„ìœ¨Â·ì¸í”„ë¼ê°•ë„ì™€ì˜ ìƒê´€ê´€ê³„
if "ê³ ë ¹ì¸êµ¬ë¹„ìœ¨" in df.columns:
    r_age = np.corrcoef(df["ê³ ë ¹ì¸êµ¬ë¹„ìœ¨"].fillna(0), df[TARGET_USED].fillna(0))[0, 1]
    direction = "ë†’ì„ìˆ˜ë¡ ì˜ë£Œíê¸°ë¬¼ì´ ì¦ê°€í•˜ëŠ” ê²½í–¥" if r_age > 0 else "ë†’ì„ìˆ˜ë¡ ì˜ë£Œíê¸°ë¬¼ì´ ê°ì†Œí•˜ëŠ” ê²½í–¥"
    insight_lines.append(
        f"- **ê³ ë ¹ì¸êµ¬ë¹„ìœ¨ê³¼ ì˜ë£Œíê¸°ë¬¼**ì˜ ìƒê´€ê³„ìˆ˜ëŠ” r â‰ˆ {r_age:.2f}ë¡œ, "
        f"ê³ ë ¹ì¸êµ¬ ë¹„ì¤‘ì´ {direction}ì„ ë³´ì…ë‹ˆë‹¤."
    )

if INFRA_COL in df.columns:
    r_infra = np.corrcoef(df[INFRA_COL].fillna(0), df[TARGET_USED].fillna(0))[0, 1]
    if r_infra > 0:
        infra_comment = "ì˜ë£Œ ì¸í”„ë¼ê°€ ë°€ì§‘ëœ ì§€ì—­ì¼ìˆ˜ë¡ ì˜ë£Œíê¸°ë¬¼ë„ í•¨ê»˜ ì¦ê°€í•˜ëŠ” 'ìˆ˜ìš” ë°˜ì˜í˜•' íŒ¨í„´"
    else:
        infra_comment = "ì¸í”„ë¼ê°€ ë°€ì§‘ëœ ì§€ì—­ì—ì„œ ì˜¤íˆë ¤ ê¸°ê´€ë‹¹ íê¸°ë¬¼ì´ ë‚®ì•„ì§€ëŠ” 'íš¨ìœ¨ì„± íš¨ê³¼' íŒ¨í„´"
    insight_lines.append(
        f"- **ì˜ë£Œì¸í”„ë¼ ê°•ë„ì™€ ì˜ë£Œíê¸°ë¬¼**ì˜ ìƒê´€ê³„ìˆ˜ëŠ” r â‰ˆ {r_infra:.2f}ë¡œ, "
        f"{infra_comment}ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤."
    )

# 3) ëŒ“ê¸€ / í…ìŠ¤íŠ¸ë¡œ ë³´ì—¬ì£¼ê¸°
if insight_lines:
    for line in insight_lines:
        st.markdown(line)
else:
    st.write("ë°ì´í„°ì—ì„œ ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì»¬ëŸ¼ êµ¬ì„±ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")





